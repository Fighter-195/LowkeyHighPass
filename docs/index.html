<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Signal Processing Cup 2026 | IIT Kanpur Lowkey High-Pass | Audio Demo with Metrics</title>
  <style>
    body {
      font-family: "Inter", sans-serif;
      background: #0d1117;
      color: #c9d1d9;
      margin: 0;
      padding: 40px;
    }
    h1, h2, h3 {
      text-align: center;
      margin: 0;
    }
    h1 {
      color: #58a6ff;
      font-size: 2.2em;
      margin-bottom: 0.2em;
    }
    h2 {
      color: #79c0ff;
      font-size: 1.6em;
      margin-bottom: 0.2em;
    }
    h3 {
      color: #c9d1d9;
      font-size: 1.1em;
      margin-bottom: 1em;
    }
    .container {
      max-width: 1200px;
      margin: 0 auto;
    }
    .controls {
      text-align: center;
      margin-bottom: 30px;
    }
    select {
      margin: 10px;
      padding: 10px;
      border-radius: 8px;
      border: none;
      background: #161b22;
      color: #c9d1d9;
      min-width: 200px;
      cursor: pointer;
    }
    .content-wrapper {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 20px;
      margin-top: 30px;
    }
    .audio-box, .metrics-box {
      padding: 20px;
      background: #161b22;
      border-radius: 12px;
      box-shadow: 0 0 10px rgba(88, 166, 255, 0.12);
    }
    .audio-box h2, .metrics-box h2 {
      color: #58a6ff;
      margin-top: 0;
    }
    audio {
      width: 100%;
      margin: 10px 0;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 12px;
    }
    th, td {
      padding: 10px;
      text-align: left;
      border-bottom: 1px solid #30363d;
    }
    th { color: #58a6ff; }
    td { color: #c9d1d9; }
    .metric-value { font-weight: 600; color: #7ee787; }
    #contentSection { display: none; }
    @media (max-width: 768px) {
      .content-wrapper { grid-template-columns: 1fr; }
      select { min-width: 160px; }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Signal Processing Cup 2026</h1>
    <h2>IIT Kanpur : Lowkey High-Pass</h2>
    <h3>ðŸŽ§ Audio Demo with Metrics â€” choose method + mixed audio</h3>

    <div class="controls">
      <div>
        <label for="method">Method:</label>
        <select id="method">
          <option value="">-- Choose Method --</option>
          <option value="neural">Neural Beamformer</option>
          <option value="two_channel">Two Channel Audio Zooming</option>
          <option value="nested">Nested Beamformer</option>
          <option value="sepformer">Sepformer</option>
          <option value="hybeam">HyBeam</option>
        </select>

        <label for="mixedFile">Mixed audio (for chosen method):</label>
        <select id="mixedFile">
          <option value="">-- Choose Mixed File --</option>
        </select>

        <button id="loadBtn">Load & Play</button>
      </div>
    </div>

    <div id="contentSection">
      <div class="content-wrapper">
        <div>
          <div class="audio-box">
            <h2>Mixed Signal</h2>
            <audio id="mixedAudio" controls>
              <source id="mixedSource" type="audio/flac">
              Your browser does not support the audio element.
            </audio>
          </div>

          <div class="audio-box">
            <h2>Model Output (primary)</h2>
            <audio id="outputAudio" controls>
              <source id="outputSource" type="audio/flac">
              Your browser does not support the audio element.
            </audio>
          </div>

          <div class="audio-box" id="extraOutputsContainer" style="display:none;">
            <h2>Additional Model Outputs</h2>
            <div id="extraOutputs"></div>
          </div>

        </div>

        <div>
          <div class="metrics-box">
            <h2>Specific Metrics</h2>
            <table>
              <thead>
                <tr><th>Metric</th><th>Score</th></tr>
              </thead>
              <tbody>
                <tr><td>STOI</td><td class="metric-value" id="stoi">--</td></tr>
                <tr><td>PESQ</td><td class="metric-value" id="pesq">--</td></tr>
                <tr><td>SNR (dB)</td><td class="metric-value" id="snr">--</td></tr>
                <tr><td>ViSQOL</td><td class="metric-value" id="visqol">--</td></tr>
              </tbody>
            </table>
          </div>

          <div class="metrics-box">
            <h2>Time Complexity Metrics</h2>
            <table>
              <thead>
                <tr><th>Metric</th><th>Value</th></tr>
              </thead>
              <tbody>
                <tr><td>Real-Time Delay</td><td class="metric-value" id="rtDelay">--</td></tr>
                <tr><td>CPU RAM</td><td class="metric-value" id="cpuRam">--</td></tr>
                <tr><td>GPU VRAM</td><td class="metric-value" id="gpuVram">--</td></tr>
                <tr><td>MACs per sec</td><td class="metric-value" id="macsPerSec">--</td></tr>
                <tr><td>Complexity</td><td class="metric-value" id="complexity">--</td></tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script>
    // Base GitHub raw path (update to your real repo if different)
    const baseURL = "https://raw.githubusercontent.com/ElectronicsClub-IITK/LowkeyHighPass/main/";

    // available mixed files per method (filenames are the suffix used in the repo)
    const mixedFilesPerMethod = {
      neural: ["female", "male", "water", "song"],
      two_channel: ["female", "male", "water", "song"],
      nested: ["female", "male", "water", "song"],
      sepformer: ["female", "male", "water", "song"],
      hybeam: ["female", "male", "water", "song"]
    };

    // specific metrics (example values) - keyed by method_mixed
    const specificMetricsData = {
      neural_female: { stoi: 0.85, pesq: 3.2, snr: 12.5, visqol: 4.1 },
      neural_male:   { stoi: 0.82, pesq: 3.0, snr: 11.8, visqol: 3.9 },
      two_channel_female: { stoi: 0.5853, pesq: 3.19, snr: 0.0, visqol: 0.0 }
      // add more keys as you compute them
    };

    // method-level metrics (example)
    const methodMetricsData = {
      neural: { rtDelay: '50ms', cpuRam: '2.5 GB', gpuVram: '4 GB', macsPerSec: '1.2M', complexity: 'O(nÂ²)' },
      two_channel: { rtDelay: '10ms', cpuRam: '512 MB', gpuVram: 'N/A', macsPerSec: '200K', complexity: 'O(n)' },
      nested: { rtDelay: '75ms', cpuRam: '3.2 GB', gpuVram: '6 GB', macsPerSec: '1.8M', complexity: 'O(nÂ² log n)' },
      sepformer: { rtDelay: '80ms', cpuRam: '1.7 GB', gpuVram: '0.0 GB', macsPerSec: '11.3G', complexity: 'O(L^2*d)' },
      hybeam: { rtDelay: '30ms', cpuRam: '13.5 MB', gpuVram: '991.23 MB', macsPerSec: '11.2M', complexity: 'O(?)' }
    };

    const methodSelect = document.getElementById('method');
    const mixedSelect = document.getElementById('mixedFile');
    const loadBtn = document.getElementById('loadBtn');
    const contentSection = document.getElementById('contentSection');

    // audio elements
    const mixedAudio = document.getElementById('mixedAudio');
    const mixedSource = document.getElementById('mixedSource');
    const outputAudio = document.getElementById('outputAudio');
    const outputSource = document.getElementById('outputSource');
    const extraOutputsContainer = document.getElementById('extraOutputsContainer');
    const extraOutputs = document.getElementById('extraOutputs');

    // metrics DOM refs
    const stoiEl = document.getElementById('stoi');
    const pesqEl = document.getElementById('pesq');
    const snrEl = document.getElementById('snr');
    const visqolEl = document.getElementById('visqol');
    const rtDelayEl = document.getElementById('rtDelay');
    const cpuRamEl = document.getElementById('cpuRam');
    const gpuVramEl = document.getElementById('gpuVram');
    const macsEl = document.getElementById('macsPerSec');
    const complexityEl = document.getElementById('complexity');

    methodSelect.addEventListener('change', onMethodChange);
    loadBtn.addEventListener('click', onLoadClick);

    function onMethodChange() {
      const method = methodSelect.value;
      // reset mixed select
      mixedSelect.innerHTML = '<option value="">-- Choose Mixed File --</option>';

      if (!method) {
        contentSection.style.display = 'none';
        return;
      }

      const files = mixedFilesPerMethod[method] || [];
      files.forEach(name => {
        // show a friendly label
        const label = name.charAt(0).toUpperCase() + name.slice(1);
        const opt = document.createElement('option');
        opt.value = name;
        opt.textContent = label;
        mixedSelect.appendChild(opt);
      });

      // show content area so user knows to choose mixed file and load
      contentSection.style.display = 'block';

      // also populate method-level metrics immediately
      const m = methodMetricsData[method] || {};
      rtDelayEl.textContent = m.rtDelay || '--';
      cpuRamEl.textContent = m.cpuRam || '--';
      gpuVramEl.textContent = m.gpuVram || '--';
      macsEl.textContent = m.macsPerSec || '--';
      complexityEl.textContent = m.complexity || '--';
    }

    function buildMixedUrl(method, mixedName) {
      // e.g. mixed_audio/neural_female_mixture.flac or mixed_audio/female_mixture.flac depending on repo structure
      // We'll try a couple of common patterns and let the browser failover if not present.
      return `${baseURL}mixed_audio/${method}_${mixedName}_mixture.flac`;
    }

    function buildOutputUrl(method, mixedName) {
      // e.g. output_audio/neural_female.flac
      return `${baseURL}output_audio/${method}_${mixedName}.flac`;
    }

    function onLoadClick() {
      const method = methodSelect.value;
      const mixed = mixedSelect.value;
      if (!method || !mixed) {
        alert('Please choose both a method and a mixed audio file.');
        return;
      }

      // set mixed audio source and load
      const mixedUrl = buildMixedUrl(method, mixed);
      console.log('Loading mixed audio from', mixedUrl);
      mixedSource.src = mixedUrl;
      mixedAudio.load();
      // attempt to autoplay (may be blocked by browsers) â€” user can click play
      // set output audio source and load
      const outputUrl = buildOutputUrl(method, mixed);
      console.log('Loading model output from', outputUrl);
      outputSource.src = outputUrl;
      outputAudio.load();

      // update specific metrics if available
      const key = `${method}_${mixed}`;
      const spec = specificMetricsData[key] || { stoi: '--', pesq: '--', snr: '--', visqol: '--' };
      stoiEl.textContent = spec.stoi;
      pesqEl.textContent = spec.pesq;
      snrEl.textContent = spec.snr;
      visqolEl.textContent = spec.visqol;

      // If you have additional model output variants, populate extraOutputs here.
      // For now we hide the extra outputs container
      extraOutputsContainer.style.display = 'none';
      extraOutputs.innerHTML = '';

      // show content section (already visible from method change) â€” ensure it's visible
      contentSection.style.display = 'block';
    }

    // helpful audio error logging
    [mixedAudio, outputAudio].forEach(a => {
      a.addEventListener('error', (e) => {
        console.error('Audio failed to load:', a.id, a.currentSrc, a.error ? a.error.code : 'unknown');
      });
    });

  </script>
</body>
</html>
