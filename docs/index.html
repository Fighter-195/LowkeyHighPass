<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Signal Processing Cup 2026 | IIT Kanpur Lowkey High-Pass | Audio Demo with Metrics</title>
  <style>
    body { font-family: "Inter", sans-serif; background: #0d1117; color: #c9d1d9; margin: 0; padding: 40px; }
    h1, h2, h3 { text-align: center; margin: 0; }
    h1 { color: #58a6ff; font-size: 2.2em; margin-bottom: 0.2em; }
    h2 { color: #79c0ff; font-size: 1.6em; margin-bottom: 0.2em; }
    h3 { color: #c9d1d9; font-size: 1.1em; margin-bottom: 1em; }
    .container { max-width: 1200px; margin: 0 auto; }
    .controls { text-align: center; margin-bottom: 30px; }
    select { margin: 10px; padding: 10px; border-radius: 8px; border: none; background: #161b22; color: #c9d1d9; min-width: 200px; cursor: pointer; }
    button { margin: 10px; padding: 10px 20px; border-radius: 8px; border: none; background: #238636; color: white; cursor: pointer; font-weight: 600; }
    button:hover { background: #2ea043; }
    .method-description { text-align: center; margin: 20px auto 0; max-width: 800px; padding: 15px 20px; background: #161b22; border-radius: 8px; border-left: 3px solid #58a6ff; }
    .method-description p { margin: 0; color: #8b949e; font-size: 0.95em; line-height: 1.5; }
    .content-wrapper { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 30px; }
    .audio-box, .metrics-box { padding: 20px; background: #161b22; border-radius: 12px; box-shadow: 0 0 10px rgba(88, 166, 255, 0.12); }
    .audio-box h2, .metrics-box h2 { color: #58a6ff; margin-top: 0; }
    audio { width: 100%; margin: 10px 0; }
    table { width: 100%; border-collapse: collapse; margin-top: 12px; }
    th, td { padding: 10px; text-align: left; border-bottom: 1px solid #30363d; }
    th { color: #58a6ff; } td { color: #c9d1d9; }
    .metric-value { font-weight: 600; color: #7ee787; }
    #contentSection { display: none; }
    @media (max-width: 768px) { .content-wrapper { grid-template-columns: 1fr; } select { min-width: 160px; } }
  </style>
</head>
<body>
  <div class="container">
    <h1>Signal Processing Cup 2026</h1>
    <h2>IIT Kanpur : Lowkey High-Pass</h2>
    <h3>ðŸŽ§ Audio Demo with Metrics â€” choose method + mixed audio</h3>

    <div class="controls">
      <label for="method">Method:</label>
      <select id="method">
        <option value="">-- Choose Method --</option>
        <option value="neural_reverb">Neural Beamformer - Reverb</option>
        <option value="two_channel_audiozooming">Two Channel AudioZooming</option>
        <option value="neural_transformer_anechoic">Neural Transformer - Anechoic</option>
        <option value="sepformer_enh">Sepformer - Enh</option>
        <option value="sepformer_enh_enh">Sepformer - Enh+Enh</option>
        <option value="dsenet">DSENet_DeepFilterNET</option>
        <option value="dsenet_final">DSENet - Final</option>
        <option value="dfsnet">DFSNET</option>
        <option value="hybeam">HyBeam</option>
        <option value="student_teacher">Student Teacher</option>
      </select>

      <label for="mixedFile">Mixed audio:</label>
      <select id="mixedFile">
        <option value="">-- Choose Mixed File --</option>
      </select>

      <button id="loadBtn">Load & Play</button>
    </div>

    <div class="method-description" id="methodDescription">
      <p id="descriptionText">Select a method to see its description here. This text provides information about the audio processing technique and its characteristics.</p>
    </div>

    <div id="contentSection">
      <div class="content-wrapper">
        <div>
          <div class="audio-box">
            <h2>Mixed Signal</h2>
            <audio id="mixedAudio" controls>
              <source id="mixedSource" type="audio/wav">
              Your browser does not support the audio element.
            </audio>
          </div>

          <div class="audio-box">
            <h2>Model Output</h2>
            <audio id="outputAudio" controls>
              <source id="outputSource" type="audio/wav">
              Your browser does not support the audio element.
            </audio>
          </div>
        </div>

        <div>
          <div class="metrics-box">
            <h2>Specific Metrics</h2>
            <table>
              <thead><tr><th>Metric</th><th>Score</th></tr></thead>
              <tbody>
                <tr><td>STOI</td><td class="metric-value" id="stoi">--</td></tr>
                <tr><td>PESQ</td><td class="metric-value" id="pesq">--</td></tr>
                <tr><td>SI-SDR (dB)</td><td class="metric-value" id="snr">--</td></tr>
              </tbody>
            </table>
          </div>

          <div class="metrics-box">
            <h2>Time Complexity Metrics</h2>
            <table>
              <thead><tr><th>Metric</th><th>Value</th></tr></thead>
              <tbody>
                <tr><td>CPU RAM</td><td class="metric-value" id="cpuRam">--</td></tr>
                <tr><td>GPU VRAM</td><td class="metric-value" id="gpuVram">--</td></tr>
                <tr><td>MACs per sec</td><td class="metric-value" id="macsPerSec">--</td></tr>
                <tr><td>Complexity</td><td class="metric-value" id="complexity">--</td></tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script>
    const baseURL = "https://raw.githubusercontent.com/ElectronicsClub-IITK/LowkeyHighPass/main/";

    // Per-method list of mixed audio filenames (without extension).
    // These live at `mixed_audio/<method>/<name>.wav`.
    const methodMixedMap = {
      neural_transformer_anechoic: ['male_female', 'anechoic_clean1'],
      dsenet_final: ['interference1', 'interference2', 'interference3', 'interference4'],
      dfsnet: ['male_female', 'dfs_test1'],
    };

    // Fallback mixed files (root folder mixed_audio/<name>.wav)
    const defaultMixedList = ['male_female', 'male_song', 'male_noise1', 'male_noise2'];

    const methodMetricsData = {
      neural_reverb: { stoi: 0.811, pesq: 1.269, snr: 3.114 },
      two_channel_audiozooming: { stoi: 0.61, pesq: 3.18, snr: 0.0 },
      neural_transformer_anechoic: { stoi: 0.853, pesq: 1.759, snr: 12.46 },
      sepformer_enh: { stoi: 0.814, pesq: 2.655, snr: -0.28 },
      sepformer_enh_enh: { stoi: 0.761, pesq: 2.077, snr: 6.79 },
      dsenet: { stoi: 0.83, pesq: 1.43, snr: 0.3 },
      dsenet_final: { stoi: 0.812, pesq: 1.641, snr: 30.645 },
      dfsnet: { stoi: 0.80, pesq: 2.50, snr: 7.50 },
      hybeam: { stoi: 0.75, pesq: 1.29, snr: 4.56 },
      student_teacher: { stoi: 0.74, pesq: 1.45, snr: 5.69 }
    };

    const timeComplexityData = {
      neural_reverb: { cpuRam: '0.0 GB', gpuVram: '0.0 GB', macsPerSec: '0.76M', complexity: '0.0' },
      two_channel_audiozooming: { cpuRam: '2.87 MB', gpuVram: 'N/A', macsPerSec: '27.3 M', complexity: 'O (F*M^3)' },
      neural_transformer_anechoic: { cpuRam: '964.31 MB', gpuVram: '268.25 MB', macsPerSec: '443317.08M', complexity: 'O(L^2*d)' },
      sepformer_enh: { cpuRam: '1.7 GB', gpuVram: '0.0 GB', macsPerSec: '11368.87M', complexity: 'O (L^2*d)' },
      sepformer_enh_enh: { cpuRam: '1.7 GB', gpuVram: '0.0 GB', macsPerSec: '11368.87M', complexity: 'O (L^2*d)' },
      dsenet: { cpuRam: 'N/A', gpuVram: '224.19 MB', macsPerSec: '3.63M', complexity: 'O (L^2*d)' },
      dsenet_final: { cpuRam: '1.6 GB', gpuVram: '0.0 GB', macsPerSec: '0.873M', complexity: 'O (L^2*d)' },
      dfsnet: { cpuRam: '1.5 GB', gpuVram: '0.0 GB', macsPerSec: '9500M', complexity: 'O (L^2*d)' },
      hybeam: { cpuRam: '13.53 MB', gpuVram: '991.23 GB', macsPerSec: '11.2M', complexity: '0.0' },
      student_teacher: { cpuRam: '927.4 MB', gpuVram: '524 MB', macsPerSec: '87354 M', complexity: 'N A' }
    };

    const methodDescriptions = {
      neural_reverb: "Neural Beamformer with reverb handling uses deep learning to focus on target audio sources while managing room acoustics. This approach combines traditional beamforming with neural networks for improved speech extraction.",
      two_channel_audiozooming: "This uses tiny time/phase differences between mics to spatially focus on the target speaker, giving much better speech isolation and noise supression than any single-mic setup.",
      neural_transformer_anechoic: "Neural Transformer in anechoic conditions leverages self-attention mechanisms for audio separation. Trained on clean recordings, it excels at isolating individual sources with high fidelity.",
      sepformer_enh: "Sepformer with enhancement combines transformer-based separation with signal processing techniques. This method balances computational efficiency with separation quality for robust audio extraction.",
      sepformer_enh_enh: "Stacking the enhancement module twice cleans leftover artifacts and makes the human voice clearer and more crisp, increasing PESQ and STOI scores.",
      dsenet: "DSENet_DeepFilterNET: DeepFilter-style architecture focused on separation + filtering. Uses the dsenet_* output audio pairs (e.g. dsenet_male_noise1.wav).",
      dsenet_final: "DSENet - Final: final/production variant of DSENet. Uses dsenet_final_* output audio pairs (e.g. dsenet_final_male_noise1.wav).",
      dfsnet: "Deep Feature Separation Network (DFSNet) extracts and separates audio sources using hierarchical feature learning. This method achieves robust separation across various acoustic conditions with moderate computational requirements.",
      hybeam: "HyBeam cleans audio using a hybrid approach: delay-and-sum processing combined with an LSTM-based FT-JNF model.",
      student_teacher: "Studentâ€“teacher lets a smaller model mimic a big one: instead of learning from true labels, the student is trained to match the large teacher modelâ€™s outputs, making it suitable for edge devices."
    };

    const methodSelect = document.getElementById('method');
    const mixedSelect = document.getElementById('mixedFile');
    const loadBtn = document.getElementById('loadBtn');
    const contentSection = document.getElementById('contentSection');
    const mixedAudio = document.getElementById('mixedAudio');
    const mixedSource = document.getElementById('mixedSource');
    const outputAudio = document.getElementById('outputAudio');
    const outputSource = document.getElementById('outputSource');
    const stoiEl = document.getElementById('stoi');
    const pesqEl = document.getElementById('pesq');
    const snrEl = document.getElementById('snr');
    const cpuRamEl = document.getElementById('cpuRam');
    const gpuVramEl = document.getElementById('gpuVram');
    const macsEl = document.getElementById('macsPerSec');
    const complexityEl = document.getElementById('complexity');
    const descriptionText = document.getElementById('descriptionText');

    const methodOutputMap = {
      two_channel_audiozooming: 'two_channel',
      dsenet: 'dsenet',
      dsenet_final: 'dsenet_final',
      neural_reverb: 'neural_reverb',
      neural_transformer_anechoic: 'neural_transformer_anechoic',
      sepformer_enh: 'sepformer_enh',
      sepformer_enh_enh: 'sepformer_enh_enh',
      dfsnet: 'dfsnet',
      hybeam: 'hybeam',
      student_teacher: 'student_teacher'
    };

    // Owner token for root fallback folder
    const ROOT_OWNER = '__root';

    // Populate mixed select for a given method.
    function populateMixedForMethod(method) {
      mixedSelect.innerHTML = '';
      const headerOpt = document.createElement('option');
      headerOpt.value = '';
      headerOpt.textContent = '-- Choose Mixed File --';
      mixedSelect.appendChild(headerOpt);

      // if the method has its own list -> owner is method and files live in mixed_audio/<method>/
      // otherwise fall back to default list and use the root folder mixed_audio/<name>.wav
      const hasOwn = Array.isArray(methodMixedMap[method]) && methodMixedMap[method].length > 0;
      const owner = hasOwn ? method : ROOT_OWNER;
      const list = hasOwn ? methodMixedMap[method] : defaultMixedList;

      if (!list || list.length === 0) {
        const opt = document.createElement('option');
        opt.value = '';
        opt.textContent = '-- No mixed available --';
        mixedSelect.appendChild(opt);
        mixedSelect.disabled = true;
        return;
      }

      mixedSelect.disabled = false;
      for (const mixedName of list) {
        const opt = document.createElement('option');
        // value encodes owner so we can build correct URLs later
        opt.value = `${owner}||${mixedName}`;
        opt.textContent = mixedName;
        mixedSelect.appendChild(opt);
      }
    }

    // Build mixed audio URL: if owner === ROOT_OWNER -> mixed_audio/<name>.wav
    // otherwise -> mixed_audio/<owner>/<name>.wav
    function buildMixedUrlFor(owner, mixedName) {
      if (owner === ROOT_OWNER) {
        return `${baseURL}mixed_audio/${mixedName}.wav`;
      } else {
        return `${baseURL}mixed_audio/${owner}/${mixedName}.wav`;
      }
    }

    // Build output audio URL (keeps your existing flat output structure)
    function buildOutputUrlFor(method, mixedName) {
      const prefix = methodOutputMap[method] || method;
      return `${baseURL}output_audio/${prefix}_${mixedName}.wav`;
    }

    methodSelect.addEventListener('change', () => {
      const method = methodSelect.value;

      if (!method) {
        contentSection.style.display = 'none';
        mixedSelect.innerHTML = '<option value="">-- Choose Mixed File --</option>';
        return;
      }

      populateMixedForMethod(method);

      const m = methodMetricsData[method];
      stoiEl.textContent = m ? m.stoi : '--';
      pesqEl.textContent = m ? m.pesq : '--';
      snrEl.textContent = m ? m.snr : '--';

      const t = timeComplexityData[method];
      cpuRamEl.textContent = t ? t.cpuRam : '--';
      gpuVramEl.textContent = t ? t.gpuVram : '--';
      macsEl.textContent = t ? t.macsPerSec : '--';
      complexityEl.textContent = t ? t.complexity : '--';

      descriptionText.textContent = methodDescriptions[method] || "Select a method to see its description here.";
      contentSection.style.display = 'block';
    });

    loadBtn.addEventListener('click', () => {
      const method = methodSelect.value;
      const mixedValue = mixedSelect.value;
      if (!method) return alert('Select a method first');
      if (!mixedValue) return alert('Select a mixed file');

      // mixedValue is encoded as "<owner>||<mixedName>"
      const [owner, mixedName] = mixedValue.split('||');
      const mixedUrl = buildMixedUrlFor(owner, mixedName);
      const outputUrl = buildOutputUrlFor(method, mixedName);

      mixedSource.src = mixedUrl;
      mixedAudio.load();

      outputSource.src = outputUrl;
      outputAudio.load();

      contentSection.style.display = 'block';
    });

    [mixedAudio, outputAudio].forEach(a => {
      a.addEventListener('error', () => {
        console.error('Audio failed to load:', a.id, a.currentSrc, a.error ? a.error.code : 'unknown');
      });
      a.addEventListener('loadeddata', () => {
        console.log(a.id, 'loaded successfully:', a.currentSrc);
      });
    });

    // Optionally set a default method on load
    // methodSelect.value = 'dsenet';
    // methodSelect.dispatchEvent(new Event('change'));
  </script>
</body>
</html>
