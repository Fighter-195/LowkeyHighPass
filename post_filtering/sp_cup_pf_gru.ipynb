{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "#  Google Drive Setup\n",
        "# =======================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR7W2l-mafQe",
        "outputId": "a10a6af5-fa46-4102-93db-0e189bff1f71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN THIS CODE IF TARGET FILES ARE IN FLAC FORMAT\n",
        "import os\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "#  CONFIGURE PATHS\n",
        "# -----------------------------\n",
        "PF_ROOT = \"/content/drive/MyDrive/pf_dataset\"   # üëà your PF dataset root\n",
        "BACKUP_FLAC = False                              # set False to delete original FLACs\n",
        "\n",
        "# -----------------------------\n",
        "#  MAIN CONVERSION LOOP\n",
        "# -----------------------------\n",
        "count = 0\n",
        "folders = [os.path.join(PF_ROOT, d) for d in os.listdir(PF_ROOT) if os.path.isdir(os.path.join(PF_ROOT, d))]\n",
        "\n",
        "for folder in tqdm(folders, desc=\"Converting FLAC ‚Üí WAV\"):\n",
        "    flac_path = os.path.join(folder, \"target.flac\")\n",
        "    wav_path  = os.path.join(folder, \"target.wav\")\n",
        "\n",
        "    if os.path.isfile(flac_path):\n",
        "        try:\n",
        "            data, fs = sf.read(flac_path, dtype=\"float32\")\n",
        "            sf.write(wav_path, data, fs)\n",
        "            count += 1\n",
        "\n",
        "            if not BACKUP_FLAC:\n",
        "                os.remove(flac_path)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error converting {flac_path}: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Converted {count} target.flac ‚Üí target.wav successfully.\")\n",
        "if BACKUP_FLAC:\n",
        "    print(\"‚ÑπÔ∏è Original FLAC files are kept. Set BACKUP_FLAC=False to delete them.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTB4vt03ao0K",
        "outputId": "6ae2300d-19d7-48d7-cfa4-527422559b0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting FLAC ‚Üí WAV: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Converted 2 target.flac ‚Üí target.wav successfully.\n",
            "‚ÑπÔ∏è Original FLAC files are kept. Set BACKUP_FLAC=False to delete them.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, gc, glob\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "id": "kZmL6_TG_zdC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATA_ROOT = '/content/drive/MyDrive/pf_dataset'\n",
        "OUT_DIR   = '/content/drive/MyDrive/ckpts_pf'\n",
        "\n",
        "# =======================\n",
        "#  PostFilter Training Code\n",
        "# =======================\n",
        "import os, json, math, gc, glob\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "FS   = 16000\n",
        "NFFT = 512\n",
        "HOP  = 256\n",
        "EPS  = 1e-8\n",
        "\n",
        "# ---------- STFT helpers ----------\n",
        "_WIN_CACHE = {}\n",
        "def _hann(device):\n",
        "    key = (device, NFFT)\n",
        "    if key not in _WIN_CACHE:\n",
        "        _WIN_CACHE[key] = torch.hann_window(NFFT, device=device)\n",
        "    return _WIN_CACHE[key]\n",
        "\n",
        "def stft(x):  return torch.stft(x, n_fft=NFFT, hop_length=HOP, window=_hann(x.device), return_complex=True)\n",
        "def istft(Xc, length): return torch.istft(Xc, n_fft=NFFT, hop_length=HOP, window=_hann(Xc.device), length=length)\n",
        "\n",
        "# ---------- Losses ----------\n",
        "def si_sdr_loss(estimate, target, eps=1e-8):\n",
        "    t_energy = torch.sum(target**2, dim=1, keepdim=True) + eps\n",
        "    scale = torch.sum(estimate * target, dim=1, keepdim=True) / t_energy\n",
        "    s_target = scale * target\n",
        "    e_noise  = estimate - s_target\n",
        "    num = torch.sum(s_target**2, dim=1) + eps\n",
        "    den = torch.sum(e_noise**2,  dim=1) + eps\n",
        "    return -10.0 * torch.log10(num / den + eps).mean()\n",
        "\n",
        "def stft_mag_loss(y_hat, y, w=0.1):\n",
        "    Yh, Yt = stft(y_hat), stft(y)\n",
        "    return w * (Yh.abs() - Yt.abs()).abs().mean()\n",
        "\n",
        "# ---------- Dataset ----------\n",
        "class PFDataset(Dataset):\n",
        "    def __init__(self, root, split=\"train\", split_file=None):\n",
        "        self.root = root\n",
        "        if split_file and os.path.isfile(split_file):\n",
        "            with open(split_file, \"r\") as f: sp = json.load(f)\n",
        "            self.ids = sp[split]\n",
        "        else:\n",
        "            all_ids = sorted([d for d in os.listdir(root) if d.startswith(\"data\")])\n",
        "            k = int(0.9 * len(all_ids))\n",
        "            self.ids = all_ids[:k] if split==\"train\" else all_ids[k:]\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "      d = self.ids[idx]\n",
        "      sub = os.path.join(self.root, d)\n",
        "      x_path = os.path.join(sub, \"nb_out.wav\")\n",
        "      y_path = os.path.join(sub, \"target.wav\")\n",
        "      if not (os.path.isfile(x_path) and os.path.isfile(y_path)):\n",
        "          # also try FLAC fallback if needed\n",
        "          if os.path.isfile(os.path.join(sub, \"nb_out.flac\")):\n",
        "              x_path = os.path.join(sub, \"nb_out.flac\")\n",
        "          if os.path.isfile(os.path.join(sub, \"target.flac\")):\n",
        "              y_path = os.path.join(sub, \"target.flac\")\n",
        "          if not (os.path.isfile(x_path) and os.path.isfile(y_path)):\n",
        "              return None\n",
        "\n",
        "      # Always get a 2-D array [T, C]\n",
        "      x_np, fs1 = sf.read(x_path, dtype=\"float32\", always_2d=True)\n",
        "      y_np, fs2 = sf.read(y_path, dtype=\"float32\", always_2d=True)\n",
        "\n",
        "      # Optional: resample to FS if mismatched\n",
        "      if fs1 != FS or fs2 != FS:\n",
        "          try:\n",
        "              import librosa\n",
        "              if fs1 != FS:\n",
        "                  x_np = librosa.resample(x_np.T, orig_sr=fs1, target_sr=FS).T\n",
        "                  fs1 = FS\n",
        "              if fs2 != FS:\n",
        "                  y_np = librosa.resample(y_np.T, orig_sr=fs2, target_sr=FS).T\n",
        "                  fs2 = FS\n",
        "          except Exception:\n",
        "              return None\n",
        "\n",
        "      # Collapse channels to mono: mean across channel axis (axis=1)\n",
        "      if x_np.shape[1] > 1:\n",
        "          x_np = np.mean(x_np, axis=1, keepdims=False)  # -> [T]\n",
        "      else:\n",
        "          x_np = x_np[:, 0]  # -> [T]\n",
        "      if y_np.shape[1] > 1:\n",
        "          y_np = np.mean(y_np, axis=1, keepdims=False)  # -> [T]\n",
        "      else:\n",
        "          y_np = y_np[:, 0]  # -> [T]\n",
        "\n",
        "      # Length match and minimal length guard\n",
        "      L = min(len(x_np), len(y_np))\n",
        "      if L < 1024:  # skip too-short pairs; STFT needs enough samples\n",
        "          return None\n",
        "\n",
        "      x = torch.from_numpy(x_np[:L])  # [T]\n",
        "      y = torch.from_numpy(y_np[:L])  # [T]\n",
        "      return {\"nb\": x, \"tgt\": y, \"length\": L}\n",
        "\n",
        "\n",
        "def collate_pad(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch: return None\n",
        "    Lmax=max(b[\"length\"] for b in batch)\n",
        "    xs,ys=[],[]\n",
        "    for b in batch:\n",
        "        pad=Lmax-b[\"length\"]\n",
        "        xs.append(torch.cat([b[\"nb\"], torch.zeros(pad)]) if pad>0 else b[\"nb\"])\n",
        "        ys.append(torch.cat([b[\"tgt\"],torch.zeros(pad)]) if pad>0 else b[\"tgt\"])\n",
        "    return {\"nb\":torch.stack(xs,0), \"tgt\":torch.stack(ys,0), \"length\":Lmax}\n",
        "\n",
        "# ---------- Model ----------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self,ch,dilation=1):\n",
        "        super().__init__()\n",
        "        self.net=nn.Sequential(\n",
        "            nn.Conv2d(ch,ch,3,padding=dilation,dilation=dilation),\n",
        "            nn.BatchNorm2d(ch), nn.LeakyReLU(0.1,True),\n",
        "            nn.Conv2d(ch,ch,3,padding=1), nn.BatchNorm2d(ch))\n",
        "        self.act=nn.LeakyReLU(0.1,True)\n",
        "    def forward(self,x): return self.act(self.net(x)+x)\n",
        "\n",
        "class PostFilterNet(nn.Module):\n",
        "    def __init__(self, n_fft=512, hop=256, hidden=128, enc_ch=64, gru_layers=1):\n",
        "        super().__init__()\n",
        "        self.n_fft = n_fft\n",
        "        self.hop = hop\n",
        "\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(2, enc_ch, 3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            ConvBlock(enc_ch, 1),\n",
        "            ConvBlock(enc_ch, 2),\n",
        "            ConvBlock(enc_ch, 4)\n",
        "        )\n",
        "        self.proj = nn.Conv2d(enc_ch, hidden, 1)\n",
        "        self.gru = nn.GRU(hidden, hidden, num_layers=gru_layers,\n",
        "                          batch_first=True, bidirectional=True)\n",
        "        self.head = nn.Conv2d(2*hidden, 2, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "    def forward(self, x):\n",
        "      print(\"HI\")\n",
        "      if x.ndim == 1:\n",
        "        x = x.unsqueeze(0)\n",
        "      elif x.ndim == 3:\n",
        "        x = x.squeeze(1)\n",
        "        print(x)\n",
        "      elif x.ndim != 2:\n",
        "        raise ValueError(f\"Unexpected input shape {x.shape}, expected [B,T] or [B,1,T]\")\n",
        "      print(x.ndim)\n",
        "      B, T = x.shape\n",
        "\n",
        "      # --- 2Ô∏è‚É£ Safety guard for short audio ---\n",
        "      if T < self.n_fft:\n",
        "          pad = self.n_fft - T\n",
        "          x = torch.nn.functional.pad(x, (0, pad))   # zero-pad to window size\n",
        "          T = x.shape[1]\n",
        "\n",
        "      # --- 3Ô∏è‚É£ Compute STFT ---\n",
        "      X = stft(x)                         # [B,F,Tf] complex\n",
        "      F, Ts = X.shape[1], X.shape[2]\n",
        "\n",
        "      # --- 4Ô∏è‚É£ Real/imag stacking for Conv2D ---\n",
        "      Xri = torch.stack([X.real, X.imag], dim=1)     # [B,2,F,Ts]\n",
        "      h = self.enc(Xri)                              # [B,C,F,Ts]\n",
        "      h = self.proj(h)                               # [B,H,F,Ts]\n",
        "\n",
        "      # --- 5Ô∏è‚É£ GRU along time per frequency ---\n",
        "      h = h.permute(0,2,3,1).reshape(B*F, Ts, -1)    # [B*F,Ts,H]\n",
        "      y,_ = self.gru(h)                              # [B*F,Ts,2H]\n",
        "      y = y.reshape(B, F, Ts, -1).permute(0,3,1,2)   # [B,2H,F,Ts]\n",
        "\n",
        "      # --- 6Ô∏è‚É£ Complex mask prediction ---\n",
        "      Mri = self.head(y)                             # [B,2,F,Ts]\n",
        "      M = self.tanh(Mri[:,0]) + 1j*self.tanh(Mri[:,1])  # complex mask ‚àà (-1,1)\n",
        "\n",
        "      # --- 7Ô∏è‚É£ Apply mask and iSTFT ---\n",
        "      Y = torch.conj(M) * X                          # filtered STFT\n",
        "      y_hat = istft(Y, length=T)                     # [B,T]\n",
        "\n",
        "      # --- 8Ô∏è‚É£ Final cleanup ---\n",
        "      y_hat = torch.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "      return y_hat\n",
        "\n",
        "\n",
        "# ---------- Train ----------\n",
        "def train_pf(data_root=DATA_ROOT,out_dir=OUT_DIR,epochs=20,batch=4,lr=2e-4,hidden=128,enc_ch=64):\n",
        "    torch.manual_seed(42)\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\",device)\n",
        "\n",
        "    tr_ds,va_ds=PFDataset(data_root,\"train\"),PFDataset(data_root,\"val\")\n",
        "    tr_dl = DataLoader(\n",
        "          dataset=tr_ds,\n",
        "          batch_size=batch,\n",
        "          shuffle=(len(tr_ds) > 1),   # shuffle only if multiple samples\n",
        "          num_workers=2,\n",
        "          pin_memory=True,\n",
        "          collate_fn=collate_pad,\n",
        "          drop_last=False\n",
        "      )\n",
        "\n",
        "    va_dl = DataLoader(\n",
        "        dataset=va_ds,\n",
        "        batch_size=batch,\n",
        "        shuffle=False,              # validation never shuffled\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        collate_fn=collate_pad,\n",
        "        drop_last=False\n",
        "      )\n",
        "\n",
        "    net=PostFilterNet(hidden=hidden,enc_ch=enc_ch).to(device)\n",
        "    opt=torch.optim.Adam(net.parameters(),lr=lr,weight_decay=1e-6)\n",
        "    sched=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,\"min\",0.5,3)\n",
        "    scaler=torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
        "    os.makedirs(out_dir,exist_ok=True)\n",
        "    best_val=float('inf')\n",
        "\n",
        "    for ep in range(1,epochs+1):\n",
        "        net.train(); tr_loss=0; nbatch=0\n",
        "        for b in tqdm(tr_dl,desc=f\"Train {ep}/{epochs}\",ncols=80):\n",
        "            if b is None: continue\n",
        "            nb=b[\"nb\"].to(device); tgt=b[\"tgt\"].to(device)\n",
        "            with torch.cuda.amp.autocast(dtype=torch.float16,enabled=(device.type==\"cuda\")):\n",
        "                y_hat=net(nb)\n",
        "                loss=0.7*si_sdr_loss(y_hat,tgt)+0.3*torch.mean(torch.abs(y_hat-tgt))\n",
        "                loss+=stft_mag_loss(y_hat,tgt,0.05)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt); scaler.update()\n",
        "            tr_loss+=float(loss.detach().cpu()); nbatch+=1\n",
        "        tr_loss/=max(1,nbatch)\n",
        "\n",
        "        net.eval(); va_loss=0; n_val=0\n",
        "        with torch.no_grad():\n",
        "            for b in va_dl:\n",
        "                if b is None: continue\n",
        "                nb=b[\"nb\"].to(device); tgt=b[\"tgt\"].to(device)\n",
        "                y_hat=net(nb)\n",
        "                loss=0.7*si_sdr_loss(y_hat,tgt)+0.3*torch.mean(torch.abs(y_hat-tgt))\n",
        "                loss+=stft_mag_loss(y_hat,tgt,0.05)\n",
        "                va_loss+=float(loss.detach().cpu()); n_val+=1\n",
        "        va_loss/=max(1,n_val)\n",
        "        print(f\"Epoch {ep}: train {tr_loss:.4f} | val {va_loss:.4f}\")\n",
        "        sched.step(va_loss)\n",
        "\n",
        "        ckpt={\"epoch\":ep,\"net\":net.state_dict(),\"opt\":opt.state_dict(),\"sched\":sched.state_dict(),\"val\":va_loss}\n",
        "        torch.save(ckpt, os.path.join(out_dir,\"pf_last.pt\"))\n",
        "        if va_loss<best_val:\n",
        "            best_val=va_loss\n",
        "            torch.save(ckpt, os.path.join(out_dir,\"pf_best.pt\"))\n",
        "            print(\"‚úî Saved new best model\")"
      ],
      "metadata": {
        "id": "7Xtdnn7KR-KB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pf(\n",
        "    data_root=DATA_ROOT,\n",
        "    out_dir=OUT_DIR,\n",
        "    epochs=6,      # bump up when you have more data\n",
        "    batch=4,       # small dataset ‚Üí batch 1\n",
        "    lr=2e-4,\n",
        "    hidden=128,\n",
        "    enc_ch=64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYKt1DFRaee1",
        "outputId": "90af9bf3-23fe-493d-dadb-d2e68dcb40be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1100105212.py:227: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler=torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 1/6:   0%|                                          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1100105212.py:236: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.float16,enabled=(device.type==\"cuda\")):\n",
            "Train 1/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "Epoch 1: train 0.0418 | val 7.8540\n",
            "‚úî Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 2/6:   0%|                                          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 2/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "Epoch 2: train -1.2769 | val 6.5628\n",
            "‚úî Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 3/6:   0%|                                          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 3/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "Epoch 3: train -2.8490 | val 5.2929\n",
            "‚úî Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 4/6:   0%|                                          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 4/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "Epoch 4: train -3.0349 | val 4.8451\n",
            "‚úî Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 5/6:   0%|                                          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 5/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "Epoch 5: train -3.0511 | val 4.8586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 6/6:   0%|                                          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 6/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "Epoch 6: train -3.4858 | val 5.1780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_one_no_target(sample_dir, ckpt_path, out_path=None):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    x_path = os.path.join(sample_dir, \"nb_out.wav\")\n",
        "\n",
        "    # 1. Load the beamformer output\n",
        "    x, fs = sf.read(x_path, dtype=\"float32\")\n",
        "    if x.ndim == 2:\n",
        "    # average the two stereo channels\n",
        "      x = np.mean(x, axis=1)\n",
        "    L = len(x)\n",
        "    x_t = torch.from_numpy(x[:L]).unsqueeze(0).to(device)\n",
        "\n",
        "    # 2. Load the PF model\n",
        "    ck = torch.load(ckpt_path, map_location=device)\n",
        "    net = PostFilterNet().to(device)\n",
        "    net.load_state_dict(ck[\"net\"])\n",
        "    net.eval()\n",
        "\n",
        "    # 3. Enhance the audio\n",
        "    y_hat = net(x_t).squeeze(0).cpu().numpy()\n",
        "\n",
        "    # 4. Save the enhanced output\n",
        "    if out_path is None:\n",
        "        out_path = os.path.join(sample_dir, \"pf_enhanced.wav\")\n",
        "    sf.write(out_path, y_hat, fs)\n",
        "    print(f\"‚úÖ Enhanced audio saved ‚Üí {out_path}\")\n"
      ],
      "metadata": {
        "id": "7TqAkx9BsVsp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_one_no_target(\n",
        "    sample_dir = \"/content/drive/MyDrive/pf_dataset/data03\",\n",
        "    ckpt_path  = \"/content/drive/MyDrive/ckpts_pf/pf_best.pt\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huixhjNjtIAn",
        "outputId": "59501f29-e0ac-4b7f-ad72-0781d854c22f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "2\n",
            "‚úÖ Enhanced audio saved ‚Üí /content/drive/MyDrive/pf_dataset/data03/pf_enhanced.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JltJimgtKlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}